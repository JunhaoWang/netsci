{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import hdbscan\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
    "import sys\n",
    "from functools import reduce\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score, accuracy_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "from networkx.algorithms import node_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def parse_index_file(filename):\n",
    "    \"\"\"Parse index file.\"\"\"\n",
    "    index = []\n",
    "    for line in open(filename):\n",
    "        index.append(int(line.strip()))\n",
    "    return index\n",
    "\n",
    "\n",
    "def sample_mask(idx, l):\n",
    "    \"\"\"Create mask.\"\"\"\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)\n",
    "\n",
    "\n",
    "def load_data(dataset_str):\n",
    "    \"\"\"\n",
    "    Loads input data from gcn/data directory\n",
    "    ind.dataset_str.x => the feature vectors of the training instances as scipy.sparse.csr.csr_matrix object;\n",
    "    ind.dataset_str.tx => the feature vectors of the test instances as scipy.sparse.csr.csr_matrix object;\n",
    "    ind.dataset_str.allx => the feature vectors of both labeled and unlabeled training instances\n",
    "        (a superset of ind.dataset_str.x) as scipy.sparse.csr.csr_matrix object;\n",
    "    ind.dataset_str.y => the one-hot labels of the labeled training instances as numpy.ndarray object;\n",
    "    ind.dataset_str.ty => the one-hot labels of the test instances as numpy.ndarray object;\n",
    "    ind.dataset_str.ally => the labels for instances in ind.dataset_str.allx as numpy.ndarray object;\n",
    "    ind.dataset_str.graph => a dict in the format {index: [index_of_neighbor_nodes]} as collections.defaultdict\n",
    "        object;\n",
    "    ind.dataset_str.test.index => the indices of test instances in graph, for the inductive setting as list object.\n",
    "    All objects above must be saved using python pickle module.\n",
    "    :param dataset_str: Dataset name\n",
    "    :return: All data input files loaded (as well the training/test data).\n",
    "    \"\"\"\n",
    "    names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
    "    objects = []\n",
    "    for i in range(len(names)):\n",
    "        with open(\"datasets/data-gcn/ind.{}.{}\".format(dataset_str, names[i]), 'rb') as f:\n",
    "            if sys.version_info > (3, 0):\n",
    "                objects.append(pkl.load(f, encoding='latin1'))\n",
    "            else:\n",
    "                objects.append(pkl.load(f))\n",
    "\n",
    "    x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
    "    test_idx_reorder = parse_index_file(\"datasets/data-gcn/ind.{}.test.index\".format(dataset_str))\n",
    "    test_idx_range = np.sort(test_idx_reorder)\n",
    "\n",
    "    if dataset_str == 'citeseer':\n",
    "        # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
    "        # Find isolated nodes, add them as zero-vecs into the right position\n",
    "        test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
    "        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
    "        tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
    "        tx = tx_extended\n",
    "        ty_extended = np.zeros((len(test_idx_range_full), y.shape[1]))\n",
    "        ty_extended[test_idx_range-min(test_idx_range), :] = ty\n",
    "        ty = ty_extended\n",
    "\n",
    "    features = sp.vstack((allx, tx)).tolil()\n",
    "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
    "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
    "\n",
    "    labels = np.vstack((ally, ty))\n",
    "\n",
    "    return adj, features, labels\n",
    "\n",
    "def data_helper(dname):\n",
    "    def sub_helper(G, keyname):\n",
    "        labels = [G.nodes[i][keyname] for i in G.nodes]\n",
    "        sorted_labels_set = sorted(list(set(labels)))\n",
    "        labels_idx = np.array(list(map(lambda x: sorted_labels_set.index(x), labels)))\n",
    "        return G, labels_idx\n",
    "    if dname in ['cora', 'citeseer', 'pubmed']:\n",
    "        adj, features, labels =load_data(dname)\n",
    "        labels_idx = np.argmax(labels, axis=-1)\n",
    "        G=nx.from_scipy_sparse_matrix(adj)\n",
    "        return G, labels_idx\n",
    "    elif dname == 'karate':\n",
    "        G=nx.karate_club_graph()\n",
    "        return sub_helper(G, 'club')\n",
    "    elif dname == 'strike':\n",
    "        G=nx.read_gml(\"datasets/real-classic/strike.gml\")\n",
    "        return sub_helper(G, 'value')\n",
    "    elif dname == 'polbooks':\n",
    "        G=nx.read_gml(\"datasets/real-classic/polbooks.gml\")\n",
    "        return sub_helper(G, 'value')\n",
    "    elif dname == 'polblogs':\n",
    "        G=nx.read_gml(\"datasets/real-classic/polblogs.gml\")\n",
    "        return sub_helper(G, 'value')\n",
    "    elif dname == 'football':\n",
    "        G=nx.read_gml(\"datasets/real-classic/football.gml\")\n",
    "        return sub_helper(G, 'value')\n",
    "    elif 'lfr' in dname:\n",
    "        mu = .1 * int(dname.split('_')[1])\n",
    "        assert mu <= .9 and mu >= .1\n",
    "        G = nx.algorithms.community.community_generators.LFR_benchmark_graph(\n",
    "            1000, 3, 1.5, mu, average_degree=5, min_degree=None, max_degree=None, \n",
    "            min_community=20, max_community=None, tol=1e-07, max_iters=500, seed=None)\n",
    "        for i in G:\n",
    "            G.nodes[i]['community_tuple'] = tuple(sorted(list( G.nodes[i]['community'])))\n",
    "        return sub_helper(G, 'community_tuple')\n",
    "    \n",
    "def partition2label(G, partition):\n",
    "    c = 0\n",
    "    node2idx = {}\n",
    "    for i in G.nodes:\n",
    "        node2idx[i] = c\n",
    "        c += 1\n",
    "    inferred_labels = np.zeros((reduce(lambda x, y: x + y, list(map(lambda z: len(z), partition)))))\n",
    "    assert len(G) == len(inferred_labels)\n",
    "    for ind, i in enumerate(partition):\n",
    "        for j in i:\n",
    "            inferred_labels[node2idx[j]] = ind\n",
    "    return inferred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_graphs = {\n",
    "    'lfr_mu_1': lambda: nx.algorithms.community.community_generators.LFR_benchmark_graph(\n",
    "        1000, 3, 1.5, 0.1, average_degree=5, min_degree=None, max_degree=None, min_community=20, \n",
    "        max_community=None, tol=1e-07, max_iters=500, seed=None),\n",
    "    'lfr_mu_5': lambda: nx.algorithms.community.community_generators.LFR_benchmark_graph(\n",
    "        1000, 3, 1.5, 0.5, average_degree=5, min_degree=None, max_degree=None, min_community=20, \n",
    "        max_community=None, tol=1e-07, max_iters=500, seed=None),\n",
    "    'lfr_mu_9': lambda: nx.algorithms.community.community_generators.LFR_benchmark_graph(\n",
    "        1000, 3, 1.5, 0.9, average_degree=5, min_degree=None, max_degree=None, min_community=20, \n",
    "        max_community=None, tol=1e-07, max_iters=500, seed=None),\n",
    "    'karate': lambda: nx.karate_club_graph(),\n",
    "    'strike': lambda: nx.read_gml(\"datasets/real-classic/strike.gml\"),\n",
    "    'football': lambda: nx.read_gml(\"datasets/real-classic/football.gml\"),\n",
    "    'polbooks': lambda: nx.read_gml(\"datasets/real-classic/polbooks.gml\"),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# node classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== cora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  9%|███████▌                                                                           | 1/11 [00:06<01:03,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== citeseer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 18%|███████████████                                                                    | 2/11 [00:18<01:12,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== pubmed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 27%|██████████████████████▋                                                            | 3/11 [03:57<09:30, 71.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== karate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 36%|██████████████████████████████▏                                                    | 4/11 [03:57<05:49, 49.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== strike\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 45%|█████████████████████████████████████▋                                             | 5/11 [03:57<03:30, 35.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== polbooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 55%|█████████████████████████████████████████████▎                                     | 6/11 [03:58<02:03, 24.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== polblogs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 64%|████████████████████████████████████████████████████▊                              | 7/11 [04:15<01:30, 22.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== football\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 73%|████████████████████████████████████████████████████████████▎                      | 8/11 [04:16<00:47, 15.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== lfr_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 82%|███████████████████████████████████████████████████████████████████▉               | 9/11 [04:18<00:23, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== lfr_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▌       | 10/11 [04:22<00:09,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== lfr_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [04:24<00:00,  7.31s/it]"
     ]
    }
   ],
   "source": [
    "performance = {}\n",
    "\n",
    "for i in ['cora', 'citeseer', 'pubmed', 'karate', 'strike', 'polbooks', 'polblogs', 'football', 'lfr_3', 'lfr_6', 'lfr_9']:\n",
    "    performance[i] = {\n",
    "        'harmonic': {\n",
    "            'test_ratio':{\n",
    "                '.2': {'acc': []},\n",
    "                '.05': {'acc': []},\n",
    "                '.5': {'acc': []},\n",
    "                '1000': {'acc': []},\n",
    "                '.95': {'acc': []},\n",
    "            }\n",
    "        },\n",
    "        'consist': {\n",
    "             'test_ratio':{\n",
    "                '.2': {'acc': []},\n",
    "                '.05': {'acc': []},\n",
    "                '.5': {'acc': []},\n",
    "                '1000': {'acc': []},\n",
    "                '.95': {'acc': []},\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "for dname in tqdm(performance):\n",
    "    print('=====', dname)\n",
    "    for r in range(10):\n",
    "        G, labels = data_helper(dname)\n",
    "        G = G.to_undirected()\n",
    "        X = list(G.nodes)\n",
    "        y = labels\n",
    "        \n",
    "        if dname in ['cora', 'citeseer', 'pubmed']:\n",
    "            test_sizes = [(1000, '1000')]\n",
    "        elif dname in ['karate', 'strike', 'polbooks', 'polblogs', 'football']:\n",
    "            test_sizes = [\n",
    "                (.05, '.05'),\n",
    "                (.5, '.5'),\n",
    "                (.95, '.95')\n",
    "            ]\n",
    "        else:\n",
    "            test_sizes = [(.2, '.2')]\n",
    "        \n",
    "        for ts, ts_key in test_sizes:\n",
    "            X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "                X, y, np.array(list(range(len(y)))), test_size=ts, random_state=42)\n",
    "            for ind, i in enumerate(X_train):\n",
    "                G.node[i]['label'] = y_train[ind]\n",
    "\n",
    "            all_inferred_labs = node_classification.harmonic_function(G)\n",
    "            test_inferred_labs = []\n",
    "            for i in idx_test:\n",
    "                test_inferred_labs.append(all_inferred_labs[i])\n",
    "            performance[dname]['harmonic']['test_ratio'][ts_key]['acc'].append(accuracy_score(y_true=y_test, y_pred=test_inferred_labs))\n",
    "\n",
    "            all_inferred_labs = node_classification.local_and_global_consistency(G)\n",
    "            test_inferred_labs = []\n",
    "            for i in idx_test:\n",
    "                test_inferred_labs.append(all_inferred_labs[i])\n",
    "            performance[dname]['consist']['test_ratio'][ts_key]['acc'].append(accuracy_score(y_true=y_test, y_pred=test_inferred_labs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dname in performance:\n",
    "    for method in performance[dname]:\n",
    "        for test_ratio in performance[dname][method]['test_ratio']:\n",
    "            if len(performance[dname][method]['test_ratio'][test_ratio]['acc']) > 0:\n",
    "                performance[dname][method]['test_ratio'][test_ratio]['acc'] = (\n",
    "                    np.mean(performance[dname][method]['test_ratio'][test_ratio]['acc']),\n",
    "                    np.std(performance[dname][method]['test_ratio'][test_ratio]['acc']),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cora': {'harmonic': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': []},\n",
       "    '.5': {'acc': []},\n",
       "    '1000': {'acc': (0.5359999999999999, 1.1102230246251565e-16)},\n",
       "    '.95': {'acc': []}}},\n",
       "  'consist': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': []},\n",
       "    '.5': {'acc': []},\n",
       "    '1000': {'acc': (0.595, 0.0)},\n",
       "    '.95': {'acc': []}}}},\n",
       " 'citeseer': {'harmonic': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': []},\n",
       "    '.5': {'acc': []},\n",
       "    '1000': {'acc': (0.462, 0.0)},\n",
       "    '.95': {'acc': []}}},\n",
       "  'consist': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': []},\n",
       "    '.5': {'acc': []},\n",
       "    '1000': {'acc': (0.514, 0.0)},\n",
       "    '.95': {'acc': []}}}},\n",
       " 'pubmed': {'harmonic': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': []},\n",
       "    '.5': {'acc': []},\n",
       "    '1000': {'acc': (0.776, 0.0)},\n",
       "    '.95': {'acc': []}}},\n",
       "  'consist': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': []},\n",
       "    '.5': {'acc': []},\n",
       "    '1000': {'acc': (0.793, 0.0)},\n",
       "    '.95': {'acc': []}}}},\n",
       " 'karate': {'harmonic': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': (1.0, 0.0)},\n",
       "    '.5': {'acc': (1.0, 0.0)},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': (1.0, 0.0)}}},\n",
       "  'consist': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': (1.0, 0.0)},\n",
       "    '.5': {'acc': (1.0, 0.0)},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': (1.0, 0.0)}}}},\n",
       " 'strike': {'harmonic': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': (1.0, 0.0)},\n",
       "    '.5': {'acc': (1.0, 0.0)},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': (1.0, 0.0)}}},\n",
       "  'consist': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': (1.0, 0.0)},\n",
       "    '.5': {'acc': (1.0, 0.0)},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': (1.0, 0.0)}}}},\n",
       " 'polbooks': {'harmonic': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': (1.0, 0.0)},\n",
       "    '.5': {'acc': (1.0, 0.0)},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': (1.0, 0.0)}}},\n",
       "  'consist': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': (1.0, 0.0)},\n",
       "    '.5': {'acc': (0.8113207547169811, 1.1102230246251565e-16)},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': (0.8699999999999999, 1.1102230246251565e-16)}}}},\n",
       " 'polblogs': {'harmonic': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': (0.9066666666666666, 0.0)},\n",
       "    '.5': {'acc': (0.9906040268456376, 1.1102230246251565e-16)},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': (0.9950564971751413, 1.1102230246251565e-16)}}},\n",
       "  'consist': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': (0.9200000000000002, 1.1102230246251565e-16)},\n",
       "    '.5': {'acc': (0.9691275167785236, 1.1102230246251565e-16)},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': (0.9745762711864406, 0.0)}}}},\n",
       " 'football': {'harmonic': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': (0.8333333333333334, 0.0)},\n",
       "    '.5': {'acc': (0.9827586206896551, 0.0)},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': (0.9909090909090909, 1.1102230246251565e-16)}}},\n",
       "  'consist': {'test_ratio': {'.2': {'acc': []},\n",
       "    '.05': {'acc': (0.8333333333333334, 0.0)},\n",
       "    '.5': {'acc': (0.9310344827586207, 0.0)},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': (0.9, 0.0)}}}},\n",
       " 'lfr_3': {'harmonic': {'test_ratio': {'.2': {'acc': (0.6969999999999998,\n",
       "      0.02749545416973502)},\n",
       "    '.05': {'acc': []},\n",
       "    '.5': {'acc': []},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': []}}},\n",
       "  'consist': {'test_ratio': {'.2': {'acc': (0.59, 0.07446475676452585)},\n",
       "    '.05': {'acc': []},\n",
       "    '.5': {'acc': []},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': []}}}},\n",
       " 'lfr_6': {'harmonic': {'test_ratio': {'.2': {'acc': (0.379,\n",
       "      0.038000000000000006)},\n",
       "    '.05': {'acc': []},\n",
       "    '.5': {'acc': []},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': []}}},\n",
       "  'consist': {'test_ratio': {'.2': {'acc': (0.25149999999999995,\n",
       "      0.06316842565712716)},\n",
       "    '.05': {'acc': []},\n",
       "    '.5': {'acc': []},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': []}}}},\n",
       " 'lfr_9': {'harmonic': {'test_ratio': {'.2': {'acc': (0.01,\n",
       "      0.005916079783099616)},\n",
       "    '.05': {'acc': []},\n",
       "    '.5': {'acc': []},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': []}}},\n",
       "  'consist': {'test_ratio': {'.2': {'acc': (0.029000000000000005,\n",
       "      0.034044089061098404)},\n",
       "    '.05': {'acc': []},\n",
       "    '.5': {'acc': []},\n",
       "    '1000': {'acc': []},\n",
       "    '.95': {'acc': []}}}}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# link prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['cora', 'citeseer', 'pubmed', 'karate', 'strike', 'polbooks', 'polblogs', 'football', 'lfr_3', 'lfr_6', 'lfr_9']:\n",
    "    \n",
    "    performance[i] = {\n",
    "        'preferential_attachment': {\n",
    "            'test_ratio':{\n",
    "                '.2': {'auc': []},\n",
    "            }\n",
    "        },\n",
    "        'resource_allocation_index': {\n",
    "             'test_ratio':{\n",
    "                '.2': {'auc': []},\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== cora\n",
      "===== citeseer\n",
      "===== pubmed\n",
      "===== karate\n",
      "===== strike\n",
      "===== polbooks\n",
      "===== polblogs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████████████████████████████████▊                              | 7/11 [00:52<00:29,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== football\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████████████████████████████████████▎                      | 8/11 [00:53<00:16,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== lfr_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████████████████████████████████████████▉               | 9/11 [00:58<00:10,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== lfr_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▌       | 10/11 [01:03<00:05,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== lfr_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [01:09<00:00,  5.47s/it]"
     ]
    }
   ],
   "source": [
    "for dname in tqdm(performance):\n",
    "    print('=====', dname)\n",
    "    if dname in ['cora', 'citeseer', 'pubmed', 'karate', 'strike', 'polbooks']:\n",
    "        continue\n",
    "    for r in range(10):\n",
    "        G, trash = data_helper(dname)\n",
    "        G = nx.Graph(G.to_undirected())\n",
    "        \n",
    "        permuted_edges = np.random.permutation(list(G.edges))\n",
    "        rm_num = int(len(permuted_edges) * .2)\n",
    "        remove_edges = permuted_edges[:rm_num]\n",
    "        keep_edges = permuted_edges[rm_num:]\n",
    "        non_edges = np.random.permutation(list(nx.non_edges(G)))[:len(permuted_edges), :]\n",
    "        \n",
    "        labs = [1] * len(permuted_edges) + [0] * len(non_edges)\n",
    "\n",
    "        remove_edges = list(map(lambda x: tuple(x), remove_edges.tolist()))\n",
    "        keep_edges = list(map(lambda x: tuple(x), keep_edges.tolist()))\n",
    "        non_edges = list(map(lambda x: tuple(x), non_edges.tolist()))\n",
    "\n",
    "        G.remove_edges_from(remove_edges)\n",
    "\n",
    "        \n",
    "        test_sizes = [(.2, '.2')]\n",
    "        \n",
    "        for ts, ts_key in test_sizes:\n",
    "            inferred_edge_scores = list(map(lambda x: x[-1], list(nx.preferential_attachment(G, remove_edges + keep_edges + non_edges))))\n",
    "        \n",
    "            performance[dname]['preferential_attachment']['test_ratio'][ts_key]['auc'].append(roc_auc_score(y_true=labs, y_score=inferred_edge_scores))\n",
    "            \n",
    "            inferred_edge_scores = list(map(lambda x: x[-1], list(nx.resource_allocation_index(G, remove_edges + keep_edges + non_edges))))\n",
    "            \n",
    "            performance[dname]['resource_allocation_index']['test_ratio'][ts_key]['auc'].append(roc_auc_score(y_true=labs, y_score=inferred_edge_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dname in performance:\n",
    "    for method in performance[dname]:\n",
    "        for test_ratio in performance[dname][method]['test_ratio']:\n",
    "            if len(performance[dname][method]['test_ratio'][test_ratio]['auc']) > 0:\n",
    "                performance[dname][method]['test_ratio'][test_ratio]['auc'] = (\n",
    "                    np.mean(performance[dname][method]['test_ratio'][test_ratio]['auc']),\n",
    "                    np.std(performance[dname][method]['test_ratio'][test_ratio]['auc']),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cora': {'preferential_attachment': {'test_ratio': {'.2': {'auc': (0.7729474485347921,\n",
       "      0.0022703950389813673)}}},\n",
       "  'resource_allocation_index': {'test_ratio': {'.2': {'auc': (0.7008298097350246,\n",
       "      0.002553756214851486)}}}},\n",
       " 'citeseer': {'preferential_attachment': {'test_ratio': {'.2': {'auc': (0.754984039314747,\n",
       "      0.0038554968029318347)}}},\n",
       "  'resource_allocation_index': {'test_ratio': {'.2': {'auc': (0.6572057385290522,\n",
       "      0.0021048644963051056)}}}},\n",
       " 'pubmed': {'preferential_attachment': {'test_ratio': {'.2': {'auc': (0.8731348548450848,\n",
       "      0.0010742849532507219)}}},\n",
       "  'resource_allocation_index': {'test_ratio': {'.2': {'auc': (0.6351894755812192,\n",
       "      0.0008977117601767371)}}}},\n",
       " 'karate': {'preferential_attachment': {'test_ratio': {'.2': {'auc': (0.8345496383957922,\n",
       "      0.023434999960498165)}}},\n",
       "  'resource_allocation_index': {'test_ratio': {'.2': {'auc': (0.6767751479289941,\n",
       "      0.03432799182592977)}}}},\n",
       " 'strike': {'preferential_attachment': {'test_ratio': {'.2': {'auc': (0.6388157894736841,\n",
       "      0.02222789425649537)}}},\n",
       "  'resource_allocation_index': {'test_ratio': {'.2': {'auc': (0.7038781163434903,\n",
       "      0.03840456989759709)}}}},\n",
       " 'polbooks': {'preferential_attachment': {'test_ratio': {'.2': {'auc': (0.7398805024655364,\n",
       "      0.011743000221225933)}}},\n",
       "  'resource_allocation_index': {'test_ratio': {'.2': {'auc': (0.8683156709395776,\n",
       "      0.009896528525282822)}}}},\n",
       " 'polblogs': {'preferential_attachment': {'test_ratio': {'.2': {'auc': (0.940366831124367,\n",
       "      0.0008723266917088203)}}},\n",
       "  'resource_allocation_index': {'test_ratio': {'.2': {'auc': (0.9320370774463986,\n",
       "      0.0013967893246971705)}}}},\n",
       " 'football': {'preferential_attachment': {'test_ratio': {'.2': {'auc': (0.5182577594213467,\n",
       "      0.009391158017620102)}}},\n",
       "  'resource_allocation_index': {'test_ratio': {'.2': {'auc': (0.8328478400293797,\n",
       "      0.005301912420011626)}}}},\n",
       " 'lfr_3': {'preferential_attachment': {'test_ratio': {'.2': {'auc': (0.6968425029740021,\n",
       "      0.018941202891843603)}}},\n",
       "  'resource_allocation_index': {'test_ratio': {'.2': {'auc': (0.5588711728875011,\n",
       "      0.006749149086165348)}}}},\n",
       " 'lfr_6': {'preferential_attachment': {'test_ratio': {'.2': {'auc': (0.700947262751077,\n",
       "      0.01576958255371179)}}},\n",
       "  'resource_allocation_index': {'test_ratio': {'.2': {'auc': (0.5150471194782917,\n",
       "      0.009247918207574462)}}}},\n",
       " 'lfr_9': {'preferential_attachment': {'test_ratio': {'.2': {'auc': (0.7064062671360423,\n",
       "      0.015698512876499135)}}},\n",
       "  'resource_allocation_index': {'test_ratio': {'.2': {'auc': (0.5101153234553508,\n",
       "      0.013469917849442813)}}}}}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
